{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-04T09:18:57.463255Z",
     "start_time": "2024-05-04T09:18:57.456709Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "#input_size = 66  # 66첫 번째 LSTM 층의 입력 크기\n",
    "sequence_length = 10  # 입력 시퀀스 길이\n",
    "batch_size = 30  # 배치 크기\n",
    "lstm_depth = 2  # LSTM 층의 깊이\n",
    "model_dimension = 75  # 모델의 hidden state 차원\n",
    "\n",
    "# hidden은 사실 초기 은닉 상태(hidden state)와 초기 셀 상태(cell state)로 구성된 튜플\n",
    "# bidirectional LSTM을 사용하므로, hidden state와 cell state의 차원은 lstm_depth * 2"
   ],
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T09:18:58.590505Z",
     "start_time": "2024-05-04T09:18:58.570607Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# random data for input\n",
    "inputs = torch.randn(sequence_length,batch_size,model_dimension)\n",
    "\n",
    "hidden = (torch.randn(lstm_depth,batch_size,model_dimension), torch.randn(lstm_depth,batch_size,model_dimension))\n",
    "print(inputs[0].shape, hidden[0].shape) "
   ],
   "id": "db2a57cc651ffca4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 75]) torch.Size([2, 30, 75])\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T09:18:59.896075Z",
     "start_time": "2024-05-04T09:18:59.875712Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Model3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model3, self).__init__()\n",
    "        self.recurrent_layer = nn.LSTM(hidden_size=100, input_size=75, bidirectional=True)\n",
    "        self.nonLin = nn.BatchNorm1d(30)\n",
    "        self.recurrent_layer2 = nn.LSTM(hidden_size=100, input_size=200, bidirectional=True) # biLSTM이라 input 2배로 늘림\n",
    "        self.nonLin2 = nn.BatchNorm1d(30)\n",
    "        self.conv = nn.Conv1d(30, 36, 7, 1)\n",
    "        self.activation = nn.ReLU()  # or Leaky ReLU activation\n",
    "        #self.dropout = nn.Dropout(0.5)\n",
    "        self.classify_layer = nn.Linear(194, 5) # LSTM 출력 차원: 100, 두 번째 nn.BatchNorm1d 출력 차원: 35, nn.Conv1d 출력 차원: 36, : 100 + 35 + 36 = 171\n",
    "\n",
    "    def forward(self, input, h_t_1=None, c_t_1=None):\n",
    "        rnn_outputs, (hn, cn) = self.recurrent_layer(input)\n",
    "        lin1 = self.nonLin(rnn_outputs)\n",
    "        rnn_outputs2, (hn2, cn2) = self.recurrent_layer2(lin1)\n",
    "        lin2 = self.nonLin2(rnn_outputs2)\n",
    "        conv = self.conv(lin2)\n",
    "        activation = self.activation(conv)\n",
    "\n",
    "        logits = self.classify_layer(activation[:,-1])\n",
    "        return logits\n"
   ],
   "id": "4f68f80ba805c6a0",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T09:13:21.750665Z",
     "start_time": "2024-05-04T09:13:21.695582Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# fusion 시도할 경우\n",
    "model_fp32 = Model3()\n",
    "\n",
    "# model must be set to eval for fusion to work\n",
    "model_fp32.eval()\n",
    "\n",
    "model_fp32.qconfig = torch.ao.quantization.get_default_qat_qconfig('x86')\n",
    "\n",
    "# fuse the activations to preceding layers, where applicable\n",
    "# this needs to be done manually depending on the model architecture\n",
    "model_fp32_fused = torch.ao.quantization.fuse_modules(model_fp32,\n",
    "    [['conv', 'activation']])\n",
    "print(model_fp32_fused)\n"
   ],
   "id": "51289f1cbe70140b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model3(\n",
      "  (recurrent_layer): LSTM(75, 100, bidirectional=True)\n",
      "  (nonLin): BatchNorm1d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (recurrent_layer2): LSTM(200, 100, bidirectional=True)\n",
      "  (nonLin2): BatchNorm1d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv): ConvReLU1d(\n",
      "    (0): Conv1d(30, 36, kernel_size=(7,), stride=(1,))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (activation): Identity()\n",
      "  (classify_layer): Linear(in_features=194, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T09:19:16.680889Z",
     "start_time": "2024-05-04T09:19:16.660772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "filepath = r'D:\\2023\\2023_1_1\\2023-RnE\\save_by_loss\\goodmodel3.pth'\n",
    "\n",
    "float_lstm = torch.load(filepath)\n",
    "\n",
    "quantized_lstm = torch.quantization.quantize_dynamic(\n",
    "    float_lstm, {nn.Linear}, dtype=torch.qint8\n",
    ")\n",
    "\n",
    "print('Here is the floating point version of this module:')\n",
    "print(float_lstm)\n",
    "print('')\n",
    "print('and now the quantized version:')\n",
    "print(quantized_lstm)\n"
   ],
   "id": "ce4135efda468964",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the floating point version of this module:\n",
      "Model3(\n",
      "  (recurrent_layer): LSTM(75, 100, bidirectional=True)\n",
      "  (nonLin): BatchNorm1d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (recurrent_layer2): LSTM(200, 100, bidirectional=True)\n",
      "  (nonLin2): BatchNorm1d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv): Conv1d(30, 36, kernel_size=(7,), stride=(1,))\n",
      "  (activation): ReLU()\n",
      "  (classify_layer): Linear(in_features=194, out_features=5, bias=True)\n",
      ")\n",
      "\n",
      "and now the quantized version:\n",
      "Model3(\n",
      "  (recurrent_layer): LSTM(75, 100, bidirectional=True)\n",
      "  (nonLin): BatchNorm1d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (recurrent_layer2): LSTM(200, 100, bidirectional=True)\n",
      "  (nonLin2): BatchNorm1d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv): Conv1d(30, 36, kernel_size=(7,), stride=(1,))\n",
      "  (activation): ReLU()\n",
      "  (classify_layer): DynamicQuantizedLinear(in_features=194, out_features=5, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T09:19:22.539219Z",
     "start_time": "2024-05-04T09:19:22.502208Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "def print_size_of_model(model, label=\"\"):\n",
    "    torch.save(model.state_dict(), \"temp.p\")\n",
    "    size=os.path.getsize(\"temp.p\")\n",
    "    print(\"model: \",label,' \\t','Size (KB):', size/1e3)\n",
    "    os.remove('temp.p')\n",
    "    return size\n",
    "\n",
    "# 규모 비교하기\n",
    "f=print_size_of_model(float_lstm,\"fp32\")\n",
    "q=print_size_of_model(quantized_lstm,\"int8\")\n",
    "print(\"{0:.2f} times smaller\".format(f/q))"
   ],
   "id": "afaa07c810f9ec2f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:  fp32  \t Size (KB): 1575.766\n",
      "model:  int8  \t Size (KB): 1573.706\n",
      "1.00 times smaller\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T06:31:04.391551Z",
     "start_time": "2024-05-04T06:31:04.384568Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_params = next(float_lstm.parameters())\n",
    "print(input_params.size())"
   ],
   "id": "fcb62629aecc4b53",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([400, 75])\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T09:19:35.895656Z",
     "start_time": "2024-05-04T09:19:29.600201Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 응답시간 살펴보기\n",
    "# 성능 비교하기\n",
    "#print(\"Floating point FP32\")\n",
    "#%timeit float_lstm.forward(inputs, hidden)\n",
    "\n",
    "print(\"Quantized INT8\")\n",
    "%timeit quantized_lstm.forward(inputs,hidden)"
   ],
   "id": "c040ef3c1a57e17a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized INT8\n",
      "7.17 ms ± 302 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T09:20:25.262942Z",
     "start_time": "2024-05-04T09:20:25.238557Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 정확도 살펴보기\n",
    "# float 모델\n",
    "logits1 = float_lstm(inputs, hidden)\n",
    "mag1 = torch.mean(abs(logits1)).item()\n",
    "print('mean absolute value of output tensor values in the FP32 model is {0:.5f} '.format(mag1))\n",
    "\n",
    "# 양자화된 모델\n",
    "logits2 = quantized_lstm(inputs, hidden)\n",
    "mag2 = torch.mean(abs(logits2)).item()\n",
    "print('mean absolute value of output tensor values in the INT8 model is {0:.5f}'.format(mag2))\n",
    "\n",
    "# 결과 비교하기\n",
    "mag3 = torch.mean(abs(logits1-logits2)).item()\n",
    "print('mean absolute value of the difference between the output tensors is {0:.5f} or {1:.2f} percent'.format(mag3,mag3/mag1*100))"
   ],
   "id": "87b1e7459be22108",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean absolute value of output tensor values in the FP32 model is 1.34337 \n",
      "mean absolute value of output tensor values in the INT8 model is 1.34120\n",
      "mean absolute value of the difference between the output tensors is 0.02205 or 1.64 percent\n"
     ]
    }
   ],
   "execution_count": 41
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
